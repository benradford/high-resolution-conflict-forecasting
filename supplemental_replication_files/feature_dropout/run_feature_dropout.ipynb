{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution Conflict Forecasting with Spatial Convolutions and Long Short-Term Memory\n",
    "\n",
    "## Replication Archive\n",
    "\n",
    "[Benjamin J. Radford](https://www.benradford.com)    \n",
    "Assistant Professor  \n",
    "UNC Charlotte  \n",
    "bradfor7@uncc.edu  \n",
    "\n",
    "This file produces all necessary data for the feature dropout study. \n",
    "\n",
    "**Warning:** This file may take several days to run depending on your computer's speed.\n",
    "\n",
    "## Imports and seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import dump, load\n",
    "\n",
    "from itertools import product\n",
    "from math import isnan\n",
    "\n",
    "import views\n",
    "from views import Period, Model, Downsampling\n",
    "from views.utils.data import assign_into_df\n",
    "from views.apps.transforms import lib as translib\n",
    "from views.apps.evaluation import lib as evallib, feature_importance as fi\n",
    "from views.apps.model import api\n",
    "from views.apps.extras import extras\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, ConvLSTM2D, Activation, Conv3D, BatchNormalization, Dropout, Bidirectional, GaussianNoise\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "import geoplot as gplt\n",
    "import contextily as ctx\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "pgid_groupa = [149426,149427,149428,149429,149430, 148706,148707,148708,148709,148710, 147986,\n",
    "147987,147988,147989,147990, 147266,147267,147268,147269,147270, 146546,146547,146548,\n",
    "146549,146550]\n",
    "\n",
    "pgid_groupb = [114918,114919,114920,114921,114922, 114198,114199,114200,114201,114202, 113478,\n",
    "113479,113480,113481,113482, 112758,112759,112760,112761,112762, 112038,112039,112040,\n",
    "112041,112042]\n",
    "\n",
    "cols_feats = [\n",
    "    \"ln_ged_best_sb\",\n",
    "    \"pgd_bdist3\",\n",
    "    \"pgd_capdist\",\n",
    "    \"pgd_agri_ih\",\n",
    "    \"pgd_pop_gpw_sum\",\n",
    "    \"pgd_ttime_mean\",\n",
    "    \"spdist_pgd_diamsec\",\n",
    "    \"pgd_pasture_ih\",\n",
    "    \"pgd_savanna_ih\",\n",
    "    \"pgd_forest_ih\",\n",
    "    \"pgd_urban_ih\",\n",
    "    \"pgd_barren_ih\",\n",
    "    \"pgd_gcp_mer\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.load_model(\"../../supplemental_data/competition_model/model_competition_entry.h5\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you wish to fetch the latest public data? If so, change False to True and run this cell\n",
    "# Cells below will fail if this is not run if you haven't imported data yourself yet.\n",
    "\n",
    "redownload_data = False\n",
    "\n",
    "if redownload_data:\n",
    "    path_zip = views.apps.data.public.fetch_latest_zip_from_website(path_dir_destination=views.DIR_SCRATCH)\n",
    "    views.apps.data.public.import_tables_and_geoms(tables=views.TABLES, geometries=views.GEOMETRIES, path_zip=path_zip)\n",
    "\n",
    "dataset = views.DATASETS[\"pgm_africa_imp_0\"]\n",
    "df = dataset.gdf\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "update = pd.read_csv(\"../../data/pgm.csv\")\n",
    "df = pd.merge(df[[\"geom\",\"pg_id\",\"month_id\"]], update, on=[\"pg_id\",\"month_id\"])\n",
    "\n",
    "df = df.loc[(df[\"year\"]<2021) & (df[\"year\"]>1989)]\n",
    "df = df.loc[(df[\"year\"]<2020) | (df[\"month\"]<9)]\n",
    "df[\"coordx\"] = df[\"geom\"].apply(lambda x: x.centroid.x)\n",
    "df[\"coordy\"] = df[\"geom\"].apply(lambda y: y.centroid.y)\n",
    "df[\"col_idx\"] = [int(a) for a in list((df[\"coordx\"] - df[\"coordx\"].min())*2)]\n",
    "df[\"row_idx\"] = [int(a) for a in list((df[\"coordy\"] - df[\"coordy\"].min())*2)]\n",
    "df[\"year_idx\"] = [int(a) for a in list((df[\"year\"] - df[\"year\"].min()))]\n",
    "df[\"month_idx\"] = [int(a) for a in list((df[\"month\"] - df[\"month\"].min()))]\n",
    "df[\"year_month_idx\"] = [int(a) for a in list((df[\"month_id\"] - df[\"month_id\"].min()))]\n",
    "\n",
    "df.drop(\"geom\", inplace=True, axis=1)\n",
    "\n",
    "\n",
    "##\n",
    "## Make Lags\n",
    "##\n",
    "df1 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df2 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df3 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df4 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df5 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df6 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df7 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "\n",
    "df1[\"year_month_idx\"] = df1[\"year_month_idx\"]+1\n",
    "df2[\"year_month_idx\"] = df2[\"year_month_idx\"]+2\n",
    "df3[\"year_month_idx\"] = df3[\"year_month_idx\"]+3\n",
    "df4[\"year_month_idx\"] = df4[\"year_month_idx\"]+4\n",
    "df5[\"year_month_idx\"] = df5[\"year_month_idx\"]+5\n",
    "df6[\"year_month_idx\"] = df6[\"year_month_idx\"]+6\n",
    "df7[\"year_month_idx\"] = df7[\"year_month_idx\"]+7\n",
    "\n",
    "df1.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l1\"]\n",
    "df2.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l2\"]\n",
    "df3.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l3\"]\n",
    "df4.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l4\"]\n",
    "df5.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l5\"]\n",
    "df6.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l6\"]\n",
    "df7.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l7\"]\n",
    "\n",
    "df = pd.merge(df,df1,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df2,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df3,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df4,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df5,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df6,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df7,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "\n",
    "df[\"delta_1\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l1\"]\n",
    "df[\"delta_2\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l2\"]\n",
    "df[\"delta_3\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l3\"]\n",
    "df[\"delta_4\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l4\"]\n",
    "df[\"delta_5\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l5\"]\n",
    "df[\"delta_6\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l6\"]\n",
    "df[\"delta_7\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l7\"]\n",
    "\n",
    "del df1\n",
    "del df2\n",
    "del df3\n",
    "del df4\n",
    "del df5\n",
    "del df6\n",
    "del df7\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "cols_ids = [\n",
    "    \"col_idx\",\n",
    "    \"row_idx\",\n",
    "    \"pg_id\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"year_idx\",\n",
    "    \"month_idx\",\n",
    "    \"year_month_idx\"]\n",
    "\n",
    "cols_lags = [\n",
    "    \"delta_1\",\n",
    "    \"delta_2\",\n",
    "    \"delta_3\",\n",
    "    \"delta_4\",\n",
    "    \"delta_5\",\n",
    "    \"delta_6\",\n",
    "    \"delta_7\"\n",
    "]\n",
    "\n",
    "df_background = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, median_var in enumerate(cols_feats):\n",
    "    print(median_var)\n",
    "\n",
    "    df = df_background.copy()\n",
    "    df.loc[df[\"pg_id\"].isin(pgid_groupa + pgid_groupb),median_var] = df[median_var].median()\n",
    "\n",
    "\n",
    "    subset = df[cols_feats+cols_ids]\n",
    "\n",
    "    ##\n",
    "    ## Fill in missing grid cells (e.g. water)\n",
    "    ## \n",
    "    all_cells = product(\n",
    "                    list(range(max(subset[\"year_month_idx\"])+1)),\n",
    "                    list(range(max(subset[\"col_idx\"])+1)),\n",
    "                    list(range(max(subset[\"row_idx\"])+1))\n",
    "                    )\n",
    "\n",
    "    all_cells = pd.DataFrame(all_cells,\n",
    "                             columns=[\"year_month_idx\",\n",
    "                                      \"col_idx\",\n",
    "                                      \"row_idx\"])\n",
    "\n",
    "    subset = pd.merge(subset, all_cells, how=\"outer\",\n",
    "                      on=[\"year_month_idx\",\n",
    "                          \"col_idx\",\n",
    "                          \"row_idx\"])\n",
    "\n",
    "    subset[\"isnan\"] = subset[cols_feats].apply(lambda x: int(any([isnan(a) for a in x])), axis=1)\n",
    "    subset.fillna(0, inplace=True)\n",
    "\n",
    "    X_grouped = subset.groupby([\"year_month_idx\",\n",
    "                              \"col_idx\",\n",
    "                              \"row_idx\"])[cols_feats+[\"isnan\"]].mean()\n",
    "    X_grouped.head()\n",
    "\n",
    "    arr = X_grouped.values.reshape((len(X_grouped.index.unique(level=0)),\n",
    "                                  len(X_grouped.index.unique(level=1)),\n",
    "                                  len(X_grouped.index.unique(level=2)),\n",
    "                                  len(cols_feats)+1))\n",
    "\n",
    "    del subset\n",
    "    gc.collect()\n",
    "\n",
    "    X = arr[:,:,:,:]\n",
    "    Y = arr[:,:,:,0]\n",
    "\n",
    "    Y1 = Y[1:] - Y[0:-1]\n",
    "    Y2 = Y[2:] - Y[0:-2]\n",
    "    Y3 = Y[3:] - Y[0:-3]\n",
    "    Y4 = Y[4:] - Y[0:-4]\n",
    "    Y5 = Y[5:] - Y[0:-5]\n",
    "    Y6 = Y[6:] - Y[0:-6]\n",
    "    Y7 = Y[7:] - Y[0:-7]\n",
    "\n",
    "    filler1 = np.full_like(np.zeros((1,178,169)),np.NaN)\n",
    "    filler2 = np.full_like(np.zeros((2,178,169)),np.NaN)\n",
    "    filler3 = np.full_like(np.zeros((3,178,169)),np.NaN)\n",
    "    filler4 = np.full_like(np.zeros((4,178,169)),np.NaN)\n",
    "    filler5 = np.full_like(np.zeros((5,178,169)),np.NaN)\n",
    "    filler6 = np.full_like(np.zeros((6,178,169)),np.NaN)\n",
    "    filler7 = np.full_like(np.zeros((7,178,169)),np.NaN)\n",
    "\n",
    "    Y1 = np.concatenate((Y1, filler1), axis=0)\n",
    "    Y2 = np.concatenate((Y2, filler2), axis=0)\n",
    "    Y3 = np.concatenate((Y3, filler3), axis=0)\n",
    "    Y4 = np.concatenate((Y4, filler4), axis=0)\n",
    "    Y5 = np.concatenate((Y5, filler5), axis=0)\n",
    "    Y6 = np.concatenate((Y6, filler6), axis=0)\n",
    "    Y7 = np.concatenate((Y7, filler7), axis=0)\n",
    "\n",
    "    YDelta = np.stack((Y1,Y2,Y3,Y4,Y5,Y6,Y7), axis=3)\n",
    "\n",
    "    del Y1\n",
    "    del Y2\n",
    "    del Y3\n",
    "    del Y4\n",
    "    del Y5\n",
    "    del Y6\n",
    "    del Y7\n",
    "    gc.collect()\n",
    "\n",
    "    pred_months = 12\n",
    "\n",
    "    all_preds = []\n",
    "\n",
    "    for ii in range(0,X.shape[0]):\n",
    "        all_preds.append( \n",
    "            np.squeeze( \n",
    "                model.predict( \n",
    "                    np.array([X[max(0,ii-pred_months+1):(ii+1)]])\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "#     np.save(\"../../supplemental_data/feature_dropout/bjr_all_preds_drop_in_\"+median_var+\".npy\", all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, median_var in enumerate(cols_feats):\n",
    "    print(median_var)\n",
    "    df = df_background.copy()\n",
    "\n",
    "    df.loc[~df[\"pg_id\"].isin(pgid_groupa + pgid_groupb),median_var] = df[median_var].median()\n",
    "\n",
    "\n",
    "    subset = df[cols_feats+cols_ids]\n",
    "\n",
    "    ##\n",
    "    ## Fill in missing grid cells (e.g. water)\n",
    "    ## \n",
    "    all_cells = product(\n",
    "                    list(range(max(subset[\"year_month_idx\"])+1)),\n",
    "                    list(range(max(subset[\"col_idx\"])+1)),\n",
    "                    list(range(max(subset[\"row_idx\"])+1))\n",
    "                    )\n",
    "\n",
    "    all_cells = pd.DataFrame(all_cells,\n",
    "                             columns=[\"year_month_idx\",\n",
    "                                      \"col_idx\",\n",
    "                                      \"row_idx\"])\n",
    "\n",
    "    subset = pd.merge(subset, all_cells, how=\"outer\",\n",
    "                      on=[\"year_month_idx\",\n",
    "                          \"col_idx\",\n",
    "                          \"row_idx\"])\n",
    "\n",
    "    subset[\"isnan\"] = subset[cols_feats].apply(lambda x: int(any([isnan(a) for a in x])), axis=1)\n",
    "    subset.fillna(0, inplace=True)\n",
    "\n",
    "    X_grouped = subset.groupby([\"year_month_idx\",\n",
    "                              \"col_idx\",\n",
    "                              \"row_idx\"])[cols_feats+[\"isnan\"]].mean()\n",
    "    X_grouped.head()\n",
    "\n",
    "    arr = X_grouped.values.reshape((len(X_grouped.index.unique(level=0)),\n",
    "                                  len(X_grouped.index.unique(level=1)),\n",
    "                                  len(X_grouped.index.unique(level=2)),\n",
    "                                  len(cols_feats)+1))\n",
    "\n",
    "    del subset\n",
    "    gc.collect()\n",
    "\n",
    "    X = arr[:,:,:,:]\n",
    "    Y = arr[:,:,:,0]\n",
    "\n",
    "    Y1 = Y[1:] - Y[0:-1]\n",
    "    Y2 = Y[2:] - Y[0:-2]\n",
    "    Y3 = Y[3:] - Y[0:-3]\n",
    "    Y4 = Y[4:] - Y[0:-4]\n",
    "    Y5 = Y[5:] - Y[0:-5]\n",
    "    Y6 = Y[6:] - Y[0:-6]\n",
    "    Y7 = Y[7:] - Y[0:-7]\n",
    "\n",
    "    filler1 = np.full_like(np.zeros((1,178,169)),np.NaN)\n",
    "    filler2 = np.full_like(np.zeros((2,178,169)),np.NaN)\n",
    "    filler3 = np.full_like(np.zeros((3,178,169)),np.NaN)\n",
    "    filler4 = np.full_like(np.zeros((4,178,169)),np.NaN)\n",
    "    filler5 = np.full_like(np.zeros((5,178,169)),np.NaN)\n",
    "    filler6 = np.full_like(np.zeros((6,178,169)),np.NaN)\n",
    "    filler7 = np.full_like(np.zeros((7,178,169)),np.NaN)\n",
    "\n",
    "    Y1 = np.concatenate((Y1, filler1), axis=0)\n",
    "    Y2 = np.concatenate((Y2, filler2), axis=0)\n",
    "    Y3 = np.concatenate((Y3, filler3), axis=0)\n",
    "    Y4 = np.concatenate((Y4, filler4), axis=0)\n",
    "    Y5 = np.concatenate((Y5, filler5), axis=0)\n",
    "    Y6 = np.concatenate((Y6, filler6), axis=0)\n",
    "    Y7 = np.concatenate((Y7, filler7), axis=0)\n",
    "\n",
    "    YDelta = np.stack((Y1,Y2,Y3,Y4,Y5,Y6,Y7), axis=3)\n",
    "\n",
    "    del Y1\n",
    "    del Y2\n",
    "    del Y3\n",
    "    del Y4\n",
    "    del Y5\n",
    "    del Y6\n",
    "    del Y7\n",
    "    gc.collect()\n",
    "\n",
    "    pred_months = 12\n",
    "\n",
    "    all_preds = []\n",
    "\n",
    "    for ii in range(0,X.shape[0]):\n",
    "        all_preds.append( \n",
    "            np.squeeze( \n",
    "                model.predict( \n",
    "                    np.array([X[max(0,ii-pred_months+1):(ii+1)]])\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "#     np.save(\"../../supplemental_data/feature_dropout/bjr_all_preds_drop_out_\"+median_var+\".npy\", all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_preds = np.load(\"../../supplemental_data/competition_model/competition_entry_predictions.npy\")\n",
    "\n",
    "out_df = df_background[[\"pg_id\",\"col_idx\",\"row_idx\",\"month_id\",\"year\",\"year_month_idx\",\n",
    "                        \"delta_1\",\"delta_2\",\"delta_3\",\"delta_4\",\"delta_5\",\"delta_6\",\"delta_7\"]].copy()\n",
    "pg_col_row = df[[\"pg_id\",\"col_idx\",\"row_idx\"]].drop_duplicates()\n",
    "pg_col_row = pd.concat([pg_col_row] * 7)\n",
    "pg_col_row[\"month_id\"] = ([489]*10677) + ([490]*10677) + ([491]*10677) + ([492]*10677) + ([493]*10677) + ([494]*10677) + ([495]*10677)\n",
    "pg_col_row[\"year_month_idx\"] = pg_col_row[\"month_id\"] - 121\n",
    "\n",
    "print(out_df.shape)\n",
    "print(pg_col_row.shape)\n",
    "out_df = pd.concat([out_df,pg_col_row])\n",
    "out_df.reset_index(inplace=True)\n",
    "print(out_df.shape)\n",
    "\n",
    "\n",
    "    \n",
    "for median_var in cols_feats:\n",
    "    new_preds = np.load(\"../../supplemental_data/feature_dropout/bjr_all_preds_drop_in_\"+median_var+\".npy\")\n",
    "    \n",
    "#     future = all_preds[-1,:,:,:]\n",
    "    \n",
    "    # out_df[[\"pred_l1\",\"pred_l2\",\"pred_l3\",\"pred_l4\",\"pred_l5\",\"pred_l6\"]] = None\n",
    "\n",
    "    preds_l1 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l2 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l3 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l4 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l5 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l6 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l7 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    \n",
    "    preds_l1_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l2_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l3_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l4_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l5_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l6_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l7_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"\\tLoop time, baby...\")\n",
    "\n",
    "    jj = 0\n",
    "\n",
    "    for ii, row in out_df.iterrows():\n",
    "\n",
    "        if jj%1000000 == 0:\n",
    "            print(f\"\\t{jj} of {out_df.shape[0]}\")\n",
    "            gc.collect()\n",
    "\n",
    "        col_idx = int(row[\"col_idx\"])\n",
    "        row_idx = int(row[\"row_idx\"])\n",
    "        year_month_idx = int(row[\"year_month_idx\"])\n",
    "\n",
    "        if year_month_idx > 0:\n",
    "            try:\n",
    "                preds_l1[jj] = all_preds[year_month_idx-1,col_idx,row_idx,0]\n",
    "                preds_l1_b[jj] = new_preds[year_month_idx-1,col_idx,row_idx,0]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 1:\n",
    "            try:\n",
    "                preds_l2[jj] = all_preds[year_month_idx-2,col_idx,row_idx,1]\n",
    "                preds_l2_b[jj] = new_preds[year_month_idx-2,col_idx,row_idx,1]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 2:\n",
    "            try:\n",
    "                preds_l3[jj] = all_preds[year_month_idx-3,col_idx,row_idx,2]\n",
    "                preds_l3_b[jj] = new_preds[year_month_idx-3,col_idx,row_idx,2]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 3:\n",
    "            try:\n",
    "                preds_l4[jj] = all_preds[year_month_idx-4,col_idx,row_idx,3]\n",
    "                preds_l4_b[jj] = new_preds[year_month_idx-4,col_idx,row_idx,3]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 4:\n",
    "            try:\n",
    "                preds_l5[jj] = all_preds[year_month_idx-5,col_idx,row_idx,4]\n",
    "                preds_l5_b[jj] = new_preds[year_month_idx-5,col_idx,row_idx,4]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 5:\n",
    "            try:\n",
    "                preds_l6[jj] = all_preds[year_month_idx-6,col_idx,row_idx,5]\n",
    "                preds_l6_b[jj] = new_preds[year_month_idx-6,col_idx,row_idx,5]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 6:\n",
    "            try:\n",
    "                preds_l7[jj] = all_preds[year_month_idx-7,col_idx,row_idx,6]\n",
    "                preds_l7_b[jj] = new_preds[year_month_idx-7,col_idx,row_idx,6]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        jj = jj+1\n",
    "\n",
    "    out_df[\"Radford_clstm_s1\"] = preds_l1\n",
    "    out_df[\"Radford_clstm_s2\"] = preds_l2\n",
    "    out_df[\"Radford_clstm_s3\"] = preds_l3\n",
    "    out_df[\"Radford_clstm_s4\"] = preds_l4\n",
    "    out_df[\"Radford_clstm_s5\"] = preds_l5\n",
    "    out_df[\"Radford_clstm_s6\"] = preds_l6\n",
    "    out_df[\"Radford_clstm_s7\"] = preds_l7\n",
    "    out_df[\"Radford_clstm_s1_drop_in_\"+median_var] = preds_l1_b\n",
    "    out_df[\"Radford_clstm_s2_drop_in_\"+median_var] = preds_l2_b\n",
    "    out_df[\"Radford_clstm_s3_drop_in_\"+median_var] = preds_l3_b\n",
    "    out_df[\"Radford_clstm_s4_drop_in_\"+median_var] = preds_l4_b\n",
    "    out_df[\"Radford_clstm_s5_drop_in_\"+median_var] = preds_l5_b\n",
    "    out_df[\"Radford_clstm_s6_drop_in_\"+median_var] = preds_l6_b\n",
    "    out_df[\"Radford_clstm_s7_drop_in_\"+median_var] = preds_l7_b\n",
    "    \n",
    "for median_var in cols_feats:\n",
    "    new_preds = np.load(\"../../supplemental_data/feature_dropout/bjr_all_preds_drop_out_\"+median_var+\".npy\")\n",
    "    \n",
    "    # out_df[[\"pred_l1\",\"pred_l2\",\"pred_l3\",\"pred_l4\",\"pred_l5\",\"pred_l6\"]] = None\n",
    "\n",
    "    preds_l1 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l2 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l3 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l4 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l5 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l6 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l7 = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    \n",
    "    preds_l1_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l2_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l3_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l4_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l5_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l6_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "    preds_l7_b = [None] * out_df.shape[0]\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"\\tLoop time, baby.\")\n",
    "\n",
    "    jj = 0\n",
    "\n",
    "    for ii, row in out_df.iterrows():\n",
    "\n",
    "        if jj%1000000 == 0:\n",
    "            print(f\"\\t{jj} of {out_df.shape[0]}\")\n",
    "            gc.collect()\n",
    "\n",
    "        col_idx = int(row[\"col_idx\"])\n",
    "        row_idx = int(row[\"row_idx\"])\n",
    "        year_month_idx = int(row[\"year_month_idx\"])\n",
    "\n",
    "        if year_month_idx > 0:\n",
    "            try:\n",
    "                preds_l1[jj] = all_preds[year_month_idx-1,col_idx,row_idx,0]\n",
    "                preds_l1_b[jj] = new_preds[year_month_idx-1,col_idx,row_idx,0]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 1:\n",
    "            try:\n",
    "                preds_l2[jj] = all_preds[year_month_idx-2,col_idx,row_idx,1]\n",
    "                preds_l2_b[jj] = new_preds[year_month_idx-2,col_idx,row_idx,1]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 2:\n",
    "            try:\n",
    "                preds_l3[jj] = all_preds[year_month_idx-3,col_idx,row_idx,2]\n",
    "                preds_l3_b[jj] = new_preds[year_month_idx-3,col_idx,row_idx,2]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 3:\n",
    "            try:\n",
    "                preds_l4[jj] = all_preds[year_month_idx-4,col_idx,row_idx,3]\n",
    "                preds_l4_b[jj] = new_preds[year_month_idx-4,col_idx,row_idx,3]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 4:\n",
    "            try:\n",
    "                preds_l5[jj] = all_preds[year_month_idx-5,col_idx,row_idx,4]\n",
    "                preds_l5_b[jj] = new_preds[year_month_idx-5,col_idx,row_idx,4]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 5:\n",
    "            try:\n",
    "                preds_l6[jj] = all_preds[year_month_idx-6,col_idx,row_idx,5]\n",
    "                preds_l6_b[jj] = new_preds[year_month_idx-6,col_idx,row_idx,5]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if year_month_idx > 6:\n",
    "            try:\n",
    "                preds_l7[jj] = all_preds[year_month_idx-7,col_idx,row_idx,6]\n",
    "                preds_l7_b[jj] = new_preds[year_month_idx-7,col_idx,row_idx,6]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        jj = jj+1\n",
    "\n",
    "    out_df[\"Radford_clstm_s1\"] = preds_l1\n",
    "    out_df[\"Radford_clstm_s2\"] = preds_l2\n",
    "    out_df[\"Radford_clstm_s3\"] = preds_l3\n",
    "    out_df[\"Radford_clstm_s4\"] = preds_l4\n",
    "    out_df[\"Radford_clstm_s5\"] = preds_l5\n",
    "    out_df[\"Radford_clstm_s6\"] = preds_l6\n",
    "    out_df[\"Radford_clstm_s7\"] = preds_l7\n",
    "    out_df[\"Radford_clstm_s1_drop_out_\"+median_var] = preds_l1_b\n",
    "    out_df[\"Radford_clstm_s2_drop_out_\"+median_var] = preds_l2_b\n",
    "    out_df[\"Radford_clstm_s3_drop_out_\"+median_var] = preds_l3_b\n",
    "    out_df[\"Radford_clstm_s4_drop_out_\"+median_var] = preds_l4_b\n",
    "    out_df[\"Radford_clstm_s5_drop_out_\"+median_var] = preds_l5_b\n",
    "    out_df[\"Radford_clstm_s6_drop_out_\"+median_var] = preds_l6_b\n",
    "    out_df[\"Radford_clstm_s7_drop_out_\"+median_var] = preds_l7_b\n",
    "    \n",
    "# out_df.to_csv(\"../../data/competition_model/feature_dropout/bjr_all_preds_drop.csv\", index=False)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:views2]",
   "language": "python",
   "name": "conda-env-views2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
