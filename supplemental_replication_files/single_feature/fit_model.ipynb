{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution Conflict Forecasting with Spatial Convolutions and Long Short-Term Memory\n",
    "\n",
    "## Replication Archive\n",
    "\n",
    "[Benjamin J. Radford](https://www.benradford.com)    \n",
    "Assistant Professor  \n",
    "UNC Charlotte  \n",
    "bradfor7@uncc.edu  \n",
    "\n",
    "This file produces, fits, and saves the Single Feature Model.\n",
    "\n",
    "## Imports and seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from joblib import dump, load\n",
    "\n",
    "from itertools import product\n",
    "from math import isnan\n",
    "\n",
    "import views\n",
    "from views import Period, Model, Downsampling\n",
    "from views.utils.data import assign_into_df\n",
    "from views.apps.transforms import lib as translib\n",
    "from views.apps.evaluation import lib as evallib, feature_importance as fi\n",
    "from views.apps.model import api\n",
    "from views.apps.extras import extras\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, ConvLSTM2D, Activation, Conv3D, BatchNormalization, Dropout, Bidirectional, GaussianNoise\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "import geoplot as gplt\n",
    "import contextily as ctx\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you wish to fetch the latest public data? If so, change False to True and run this cell\n",
    "# Cells below will fail if this is not run if you haven't imported data yourself yet.\n",
    "redownload_data = False\n",
    "\n",
    "if redownload_data:\n",
    "    path_zip = views.apps.data.public.fetch_latest_zip_from_website(path_dir_destination=views.DIR_SCRATCH)\n",
    "    views.apps.data.public.import_tables_and_geoms(tables=views.TABLES, geometries=views.GEOMETRIES, path_zip=path_zip)\n",
    "\n",
    "dataset = views.DATASETS[\"pgm_africa_imp_0\"]\n",
    "df = dataset.gdf\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "update = pd.read_csv(\"../../data/pgm.csv\")\n",
    "df = pd.merge(df[[\"geom\",\"pg_id\",\"month_id\"]], update, on=[\"pg_id\",\"month_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[(df[\"year\"]<2021) & (df[\"year\"]>1989)]\n",
    "df = df.loc[(df[\"year\"]<2020) | (df[\"month\"]<9)]\n",
    "df[\"coordx\"] = df[\"geom\"].apply(lambda x: x.centroid.x)\n",
    "df[\"coordy\"] = df[\"geom\"].apply(lambda y: y.centroid.y)\n",
    "df[\"col_idx\"] = [int(a) for a in list((df[\"coordx\"] - df[\"coordx\"].min())*2)]\n",
    "df[\"row_idx\"] = [int(a) for a in list((df[\"coordy\"] - df[\"coordy\"].min())*2)]\n",
    "df[\"year_idx\"] = [int(a) for a in list((df[\"year\"] - df[\"year\"].min()))]\n",
    "df[\"month_idx\"] = [int(a) for a in list((df[\"month\"] - df[\"month\"].min()))]\n",
    "df[\"year_month_idx\"] = [int(a) for a in list((df[\"month_id\"] - df[\"month_id\"].min()))]\n",
    "\n",
    "df.drop(\"geom\", inplace=True, axis=1)\n",
    "\n",
    "\n",
    "##\n",
    "## Make Lags\n",
    "##\n",
    "df1 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df2 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df3 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df4 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df5 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df6 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "df7 = df[[\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb\"]].copy()\n",
    "\n",
    "df1[\"year_month_idx\"] = df1[\"year_month_idx\"]+1\n",
    "df2[\"year_month_idx\"] = df2[\"year_month_idx\"]+2\n",
    "df3[\"year_month_idx\"] = df3[\"year_month_idx\"]+3\n",
    "df4[\"year_month_idx\"] = df4[\"year_month_idx\"]+4\n",
    "df5[\"year_month_idx\"] = df5[\"year_month_idx\"]+5\n",
    "df6[\"year_month_idx\"] = df6[\"year_month_idx\"]+6\n",
    "df7[\"year_month_idx\"] = df7[\"year_month_idx\"]+7\n",
    "\n",
    "df1.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l1\"]\n",
    "df2.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l2\"]\n",
    "df3.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l3\"]\n",
    "df4.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l4\"]\n",
    "df5.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l5\"]\n",
    "df6.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l6\"]\n",
    "df7.columns = [\"year_month_idx\",\"pg_id\",\"ln_ged_best_sb_l7\"]\n",
    "\n",
    "df = pd.merge(df,df1,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df2,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df3,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df4,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df5,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df6,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "df = pd.merge(df,df7,how=\"left\",on=[\"year_month_idx\",\"pg_id\"])\n",
    "\n",
    "df[\"delta_1\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l1\"]\n",
    "df[\"delta_2\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l2\"]\n",
    "df[\"delta_3\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l3\"]\n",
    "df[\"delta_4\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l4\"]\n",
    "df[\"delta_5\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l5\"]\n",
    "df[\"delta_6\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l6\"]\n",
    "df[\"delta_7\"] = df[\"ln_ged_best_sb\"] - df[\"ln_ged_best_sb_l7\"]\n",
    "\n",
    "del df1\n",
    "del df2\n",
    "del df3\n",
    "del df4\n",
    "del df5\n",
    "del df6\n",
    "del df7\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ids = [\n",
    "    \"col_idx\",\n",
    "    \"row_idx\",\n",
    "    \"pg_id\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"year_idx\",\n",
    "    \"month_idx\",\n",
    "    \"year_month_idx\"]\n",
    "\n",
    "cols_feats = [\n",
    "    \"ln_ged_best_sb\",\n",
    "    \"pgd_bdist3\",\n",
    "    \"pgd_capdist\",\n",
    "    \"pgd_agri_ih\",\n",
    "    \"pgd_pop_gpw_sum\",\n",
    "    \"pgd_ttime_mean\",\n",
    "    \"spdist_pgd_diamsec\",\n",
    "    \"pgd_pasture_ih\",\n",
    "    \"pgd_savanna_ih\",\n",
    "    \"pgd_forest_ih\",\n",
    "    \"pgd_urban_ih\",\n",
    "    \"pgd_barren_ih\",\n",
    "    \"pgd_gcp_mer\"\n",
    "]\n",
    "\n",
    "cols_lags = [\n",
    "    \"delta_1\",\n",
    "    \"delta_2\",\n",
    "    \"delta_3\",\n",
    "    \"delta_4\",\n",
    "    \"delta_5\",\n",
    "    \"delta_6\",\n",
    "    \"delta_7\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 178, 169, 14)\n"
     ]
    }
   ],
   "source": [
    "subset = df[cols_feats+cols_ids]\n",
    "\n",
    "##\n",
    "## Fill in missing grid cells (e.g. water)\n",
    "## \n",
    "all_cells = product(\n",
    "                list(range(max(subset[\"year_month_idx\"])+1)),\n",
    "                list(range(max(subset[\"col_idx\"])+1)),\n",
    "                list(range(max(subset[\"row_idx\"])+1))\n",
    "                )\n",
    "\n",
    "all_cells = pd.DataFrame(all_cells,\n",
    "                         columns=[\"year_month_idx\",\n",
    "                                  \"col_idx\",\n",
    "                                  \"row_idx\"])\n",
    "\n",
    "subset = pd.merge(subset, all_cells, how=\"outer\",\n",
    "                  on=[\"year_month_idx\",\n",
    "                      \"col_idx\",\n",
    "                      \"row_idx\"])\n",
    "\n",
    "subset[\"isnan\"] = subset[cols_feats].apply(lambda x: int(any([isnan(a) for a in x])), axis=1)\n",
    "subset.fillna(0, inplace=True)\n",
    "\n",
    "X_grouped = subset.groupby([\"year_month_idx\",\n",
    "                          \"col_idx\",\n",
    "                          \"row_idx\"])[cols_feats+[\"isnan\"]].mean()\n",
    "X_grouped.head()\n",
    "\n",
    "arr = X_grouped.values.reshape((len(X_grouped.index.unique(level=0)),\n",
    "                              len(X_grouped.index.unique(level=1)),\n",
    "                              len(X_grouped.index.unique(level=2)),\n",
    "                              len(cols_feats)+1))\n",
    "\n",
    "del subset\n",
    "gc.collect()\n",
    "\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = arr[:,:,:,:]\n",
    "Y = arr[:,:,:,0]\n",
    "\n",
    "Y1 = Y[1:] - Y[0:-1]\n",
    "Y2 = Y[2:] - Y[0:-2]\n",
    "Y3 = Y[3:] - Y[0:-3]\n",
    "Y4 = Y[4:] - Y[0:-4]\n",
    "Y5 = Y[5:] - Y[0:-5]\n",
    "Y6 = Y[6:] - Y[0:-6]\n",
    "Y7 = Y[7:] - Y[0:-7]\n",
    "\n",
    "filler1 = np.full_like(np.zeros((1,178,169)),np.NaN)\n",
    "filler2 = np.full_like(np.zeros((2,178,169)),np.NaN)\n",
    "filler3 = np.full_like(np.zeros((3,178,169)),np.NaN)\n",
    "filler4 = np.full_like(np.zeros((4,178,169)),np.NaN)\n",
    "filler5 = np.full_like(np.zeros((5,178,169)),np.NaN)\n",
    "filler6 = np.full_like(np.zeros((6,178,169)),np.NaN)\n",
    "filler7 = np.full_like(np.zeros((7,178,169)),np.NaN)\n",
    "\n",
    "Y1 = np.concatenate((Y1, filler1), axis=0)\n",
    "Y2 = np.concatenate((Y2, filler2), axis=0)\n",
    "Y3 = np.concatenate((Y3, filler3), axis=0)\n",
    "Y4 = np.concatenate((Y4, filler4), axis=0)\n",
    "Y5 = np.concatenate((Y5, filler5), axis=0)\n",
    "Y6 = np.concatenate((Y6, filler6), axis=0)\n",
    "Y7 = np.concatenate((Y7, filler7), axis=0)\n",
    "\n",
    "YDelta = np.stack((Y1,Y2,Y3,Y4,Y5,Y6,Y7), axis=3)\n",
    "\n",
    "del Y1\n",
    "del Y2\n",
    "del Y3\n",
    "del Y4\n",
    "del Y5\n",
    "del Y6\n",
    "del Y7\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 178, 169, 14)\n",
      "(368, 178, 169)\n",
      "(368, 178, 169, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(YDelta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 178, 169, 14)\n",
      "(368, 178, 169, 7)\n"
     ]
    }
   ],
   "source": [
    "pred_months = 12\n",
    "\n",
    "print(X.shape)\n",
    "print(YDelta.shape)\n",
    "\n",
    "train_idx = range(pred_months, 12 * 23 + 6)\n",
    "validate_idx = range(12 * 23 + 6, 12 * 26 + 6)\n",
    "test_idx = range(12 * 26 + 6, 12 * 30 + 7)\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_validate = []\n",
    "Y_validate = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for ii in range(X.shape[0]):\n",
    "    if ii in train_idx:\n",
    "        X_train.append(X[(ii-pred_months):ii])\n",
    "        Y_train.append(YDelta[ii-1])\n",
    "    if ii in validate_idx:\n",
    "        X_validate.append(X[(ii-pred_months):ii])\n",
    "        Y_validate.append(YDelta[ii-1])\n",
    "    if ii in test_idx:\n",
    "        X_test.append(X[(ii-pred_months):ii])\n",
    "        Y_test.append(YDelta[ii-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack(X_train)\n",
    "Y_train = np.stack(Y_train)\n",
    "X_validate = np.stack(X_validate)\n",
    "Y_validate = np.stack(Y_validate)\n",
    "X_test = np.stack(X_test)\n",
    "Y_test = np.stack(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 12, 178, 169, 1)\n",
      "(270, 178, 169, 7)\n",
      "(36, 12, 178, 169, 1)\n",
      "(36, 178, 169, 7)\n",
      "(49, 12, 178, 169, 1)\n",
      "(49, 178, 169, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[:,:,:,:,0:1]\n",
    "X_validate = X_validate[:,:,:,:,0:1]\n",
    "X_test = X_test[:,:,:,:,0:1]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_validate.shape)\n",
    "print(Y_validate.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_layer = Input(shape=(None, 178, 169, 1))\n",
    "norm = BatchNormalization()(in_layer)\n",
    "conv_layer_3 = Conv3D(filters=20,\n",
    "                      kernel_size=(1,1,14),\n",
    "                      activation=\"tanh\",\n",
    "                      padding=\"same\")(norm)\n",
    "conv_lstm_1 = Bidirectional(ConvLSTM2D(10,\n",
    "                         kernel_size = (10,10),\n",
    "                         activation = \"tanh\",\n",
    "                         padding = \"same\",\n",
    "                         return_sequences=True))(Dropout(0.2)(conv_layer_3))\n",
    "conv_lstm_2 = Bidirectional(ConvLSTM2D(5,\n",
    "                         kernel_size = (5,5),\n",
    "                         activation = \"tanh\",\n",
    "                         padding = \"same\",\n",
    "                         return_sequences=True))(Dropout(0.2)(conv_lstm_1))\n",
    "conv_lstm_3 = ConvLSTM2D(7,\n",
    "                         kernel_size = (5,5),\n",
    "                         activation = \"linear\",\n",
    "                         padding = \"same\",\n",
    "                         return_sequences=False)(Dropout(0.2)(conv_lstm_2))\n",
    "\n",
    "# output = tf.keras.backend.squeeze(conv_lstm_2, axis=3)\n",
    "\n",
    "\n",
    "model = Model(inputs=in_layer,\n",
    "              outputs=conv_lstm_3)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "                      loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Output Shape                            Param #        \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)                         [(None, None, 178, 169, 1)]             0              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization (BatchNormalization)     (None, None, 178, 169, 1)               4              \n",
      "____________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                              (None, None, 178, 169, 20)              300            \n",
      "____________________________________________________________________________________________________\n",
      "dropout (Dropout)                            (None, None, 178, 169, 20)              0              \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)                (None, None, 178, 169, 20)              240080         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                          (None, None, 178, 169, 20)              0              \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)              (None, None, 178, 169, 10)              25040          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                          (None, None, 178, 169, 10)              0              \n",
      "____________________________________________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)                  (None, 178, 169, 7)                     11928          \n",
      "====================================================================================================\n",
      "Total params: 277,352\n",
      "Trainable params: 277,350\n",
      "Non-trainable params: 2\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model\n",
    "\n",
    "Uncomment to fit the model. This is only necessary if you do not want to use the pre-trained model provided in the replication materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x=X_train,\n",
    "#         y=Y_train,\n",
    "#         batch_size=8,\n",
    "#         epochs=75,\n",
    "#         validation_data=(X_validate,Y_validate)\n",
    "#        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load model\n",
    "\n",
    "Uncomment `model.save(...)` to save your newly trained model. **Warning:** this will overwrite the original model from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 178, 169, 1 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 178, 169, 1) 4         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, None, 178, 169, 20 300       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 178, 169, 20 0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 178, 169, 20 240080    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 178, 169, 20 0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 178, 169, 10 25040     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 178, 169, 10 0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 178, 169, 7)       11928     \n",
      "=================================================================\n",
      "Total params: 277,352\n",
      "Trainable params: 277,350\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"../../supplemental_data/single_feature/model_single_feature.h5\")\n",
    "model = keras.models.load_model(\"../../supplemental_data/single_feature/model_single_feature.h5\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f811baf7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f811baf7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f811baf7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f811baf7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f811baf7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f811baf7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f811baf7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f811baf7ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30081"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "for ii in range(0,X.shape[0]):\n",
    "    all_preds.append( \n",
    "        np.squeeze( \n",
    "            model.predict( \n",
    "                np.array([X[max(0,ii-pred_months+1):(ii+1),:,:,0:1]])\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions as Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(368, 178, 169, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds = np.stack(all_preds)\n",
    "np.save(\"../../supplemental_data/single_feature/single_feature_predictions.npy\", all_preds)\n",
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:views2]",
   "language": "python",
   "name": "conda-env-views2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
